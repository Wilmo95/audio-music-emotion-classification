{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import librosa\n",
    "\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "DURATION = 20\n",
    "OFFSET = 10\n",
    "SAMPLING_RATE = 16000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"audio/classical/5.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_audio(file_path):\n",
    "#     data = tf.io.read_file(file_path)\n",
    "#     wave, _ = librosa.stft(data)\n",
    "#     return wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(\n",
    "    file_path, sampling_rate=SAMPLING_RATE, duration=DURATION, offset=OFFSET\n",
    "):\n",
    "    if duration + offset >= int(librosa.get_duration(filename=file_path)):\n",
    "        offset = 0\n",
    "    data, _ = librosa.load(\n",
    "        path=str(file_path), sr=sampling_rate, duration=duration, offset=offset\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_audio(p)\n",
    "# ipd.Audio(data, rate=SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spec(y):\n",
    "    return np.abs(librosa.stft(y, n_fft=255, hop_length=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = get_spec(data)\n",
    "# d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path):\n",
    "    data_csv = pd.read_csv(path, skipinitialspace=True)\n",
    "    labels = data_csv.drop(\n",
    "        columns=[\"mood\", \"age\", \"gender\", \"disliked\", \"liked\", \"mother tongue\", \"genre\"]\n",
    "    )  # unnecessary columns\n",
    "    labels = labels.groupby(\"track id\").mean()\n",
    "    for column in labels.columns:\n",
    "        labels[column] = labels[column].apply(lambda x: 1 if (x >= 0.5) else 0)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "y = load_csv(\"data.csv\")\n",
    "target = tf.data.Dataset.from_tensor_slices(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio\\classical\\1.mp3\n",
      "audio\\classical\\2.mp3\n",
      "audio\\classical\\3.mp3\n",
      "audio\\classical\\4.mp3\n",
      "audio\\classical\\5.mp3\n",
      "audio\\classical\\6.mp3\n",
      "audio\\classical\\7.mp3\n",
      "audio\\classical\\8.mp3\n",
      "audio\\classical\\9.mp3\n",
      "audio\\classical\\10.mp3\n",
      "audio\\classical\\11.mp3\n",
      "audio\\classical\\12.mp3\n",
      "audio\\classical\\13.mp3\n",
      "audio\\classical\\14.mp3\n",
      "audio\\classical\\15.mp3\n",
      "audio\\classical\\16.mp3\n",
      "audio\\classical\\17.mp3\n",
      "audio\\classical\\18.mp3\n",
      "audio\\classical\\19.mp3\n",
      "audio\\classical\\20.mp3\n",
      "audio\\classical\\21.mp3\n",
      "audio\\classical\\22.mp3\n",
      "audio\\classical\\23.mp3\n",
      "audio\\classical\\24.mp3\n",
      "audio\\classical\\25.mp3\n",
      "audio\\classical\\26.mp3\n",
      "audio\\classical\\27.mp3\n",
      "audio\\classical\\28.mp3\n",
      "audio\\classical\\29.mp3\n",
      "audio\\classical\\30.mp3\n",
      "audio\\classical\\31.mp3\n",
      "audio\\classical\\32.mp3\n",
      "audio\\classical\\33.mp3\n",
      "audio\\classical\\34.mp3\n",
      "audio\\classical\\35.mp3\n",
      "audio\\classical\\36.mp3\n",
      "audio\\classical\\37.mp3\n",
      "audio\\classical\\38.mp3\n",
      "audio\\classical\\39.mp3\n",
      "audio\\classical\\40.mp3\n",
      "audio\\classical\\41.mp3\n",
      "audio\\classical\\42.mp3\n",
      "audio\\classical\\43.mp3\n",
      "audio\\classical\\44.mp3\n",
      "audio\\classical\\45.mp3\n",
      "audio\\classical\\46.mp3\n",
      "audio\\classical\\47.mp3\n",
      "audio\\classical\\48.mp3\n",
      "audio\\classical\\49.mp3\n",
      "audio\\classical\\50.mp3\n",
      "audio\\classical\\51.mp3\n",
      "audio\\classical\\52.mp3\n",
      "audio\\classical\\53.mp3\n",
      "audio\\classical\\54.mp3\n",
      "audio\\classical\\55.mp3\n",
      "audio\\classical\\56.mp3\n",
      "audio\\classical\\57.mp3\n",
      "audio\\classical\\58.mp3\n",
      "audio\\classical\\59.mp3\n",
      "audio\\classical\\60.mp3\n",
      "audio\\classical\\61.mp3\n",
      "audio\\classical\\62.mp3\n",
      "audio\\classical\\63.mp3\n",
      "audio\\classical\\64.mp3\n",
      "audio\\classical\\65.mp3\n",
      "audio\\classical\\66.mp3\n",
      "audio\\classical\\67.mp3\n",
      "audio\\classical\\68.mp3\n",
      "audio\\classical\\69.mp3\n",
      "audio\\classical\\70.mp3\n",
      "audio\\classical\\71.mp3\n",
      "audio\\classical\\72.mp3\n",
      "audio\\classical\\73.mp3\n",
      "audio\\classical\\74.mp3\n",
      "audio\\classical\\75.mp3\n",
      "audio\\classical\\76.mp3\n",
      "audio\\classical\\77.mp3\n",
      "audio\\classical\\78.mp3\n",
      "audio\\classical\\79.mp3\n",
      "audio\\classical\\80.mp3\n",
      "audio\\classical\\81.mp3\n",
      "audio\\classical\\82.mp3\n",
      "audio\\classical\\83.mp3\n",
      "audio\\classical\\84.mp3\n",
      "audio\\classical\\85.mp3\n",
      "audio\\classical\\86.mp3\n",
      "audio\\classical\\87.mp3\n",
      "audio\\classical\\88.mp3\n",
      "audio\\classical\\89.mp3\n",
      "audio\\classical\\90.mp3\n",
      "audio\\classical\\91.mp3\n",
      "audio\\classical\\92.mp3\n",
      "audio\\classical\\93.mp3\n",
      "audio\\classical\\94.mp3\n",
      "audio\\classical\\95.mp3\n",
      "audio\\classical\\96.mp3\n",
      "audio\\classical\\97.mp3\n",
      "audio\\classical\\98.mp3\n",
      "audio\\classical\\99.mp3\n",
      "audio\\classical\\100.mp3\n",
      "audio\\electronic\\1.mp3\n",
      "audio\\electronic\\2.mp3\n",
      "audio\\electronic\\3.mp3\n",
      "audio\\electronic\\4.mp3\n",
      "audio\\electronic\\5.mp3\n",
      "audio\\electronic\\6.mp3\n",
      "audio\\electronic\\7.mp3\n",
      "audio\\electronic\\8.mp3\n",
      "audio\\electronic\\9.mp3\n",
      "audio\\electronic\\10.mp3\n",
      "audio\\electronic\\11.mp3\n",
      "audio\\electronic\\12.mp3\n",
      "audio\\electronic\\13.mp3\n",
      "audio\\electronic\\14.mp3\n",
      "audio\\electronic\\15.mp3\n",
      "audio\\electronic\\16.mp3\n",
      "audio\\electronic\\17.mp3\n",
      "audio\\electronic\\18.mp3\n",
      "audio\\electronic\\19.mp3\n",
      "audio\\electronic\\20.mp3\n",
      "audio\\electronic\\21.mp3\n",
      "audio\\electronic\\22.mp3\n",
      "audio\\electronic\\23.mp3\n",
      "audio\\electronic\\24.mp3\n",
      "audio\\electronic\\25.mp3\n",
      "audio\\electronic\\26.mp3\n",
      "audio\\electronic\\27.mp3\n",
      "audio\\electronic\\28.mp3\n",
      "audio\\electronic\\29.mp3\n",
      "audio\\electronic\\30.mp3\n",
      "audio\\electronic\\31.mp3\n",
      "audio\\electronic\\32.mp3\n",
      "audio\\electronic\\33.mp3\n",
      "audio\\electronic\\34.mp3\n",
      "audio\\electronic\\35.mp3\n",
      "audio\\electronic\\36.mp3\n",
      "audio\\electronic\\37.mp3\n",
      "audio\\electronic\\38.mp3\n",
      "audio\\electronic\\39.mp3\n",
      "audio\\electronic\\40.mp3\n",
      "audio\\electronic\\41.mp3\n",
      "audio\\electronic\\42.mp3\n",
      "audio\\electronic\\43.mp3\n",
      "audio\\electronic\\44.mp3\n",
      "audio\\electronic\\45.mp3\n",
      "audio\\electronic\\46.mp3\n",
      "audio\\electronic\\47.mp3\n",
      "audio\\electronic\\48.mp3\n",
      "audio\\electronic\\49.mp3\n",
      "audio\\electronic\\50.mp3\n",
      "audio\\electronic\\51.mp3\n",
      "audio\\electronic\\52.mp3\n",
      "audio\\electronic\\53.mp3\n",
      "audio\\electronic\\54.mp3\n",
      "audio\\electronic\\55.mp3\n",
      "audio\\electronic\\56.mp3\n",
      "audio\\electronic\\57.mp3\n",
      "audio\\electronic\\58.mp3\n",
      "audio\\electronic\\59.mp3\n",
      "audio\\electronic\\60.mp3\n",
      "audio\\electronic\\61.mp3\n",
      "audio\\electronic\\62.mp3\n",
      "audio\\electronic\\63.mp3\n",
      "audio\\electronic\\64.mp3\n",
      "audio\\electronic\\65.mp3\n",
      "audio\\electronic\\66.mp3\n",
      "audio\\electronic\\67.mp3\n",
      "audio\\electronic\\68.mp3\n",
      "audio\\electronic\\69.mp3\n",
      "audio\\electronic\\70.mp3\n",
      "audio\\electronic\\71.mp3\n",
      "audio\\electronic\\72.mp3\n",
      "audio\\electronic\\73.mp3\n",
      "audio\\electronic\\74.mp3\n",
      "audio\\electronic\\75.mp3\n",
      "audio\\electronic\\76.mp3\n",
      "audio\\electronic\\77.mp3\n",
      "audio\\electronic\\78.mp3\n",
      "audio\\electronic\\79.mp3\n",
      "audio\\electronic\\80.mp3\n",
      "audio\\electronic\\81.mp3\n",
      "audio\\electronic\\82.mp3\n",
      "audio\\electronic\\83.mp3\n",
      "audio\\electronic\\84.mp3\n",
      "audio\\electronic\\85.mp3\n",
      "audio\\electronic\\86.mp3\n",
      "audio\\electronic\\87.mp3\n",
      "audio\\electronic\\88.mp3\n",
      "audio\\electronic\\89.mp3\n",
      "audio\\electronic\\90.mp3\n",
      "audio\\electronic\\91.mp3\n",
      "audio\\electronic\\92.mp3\n",
      "audio\\electronic\\93.mp3\n",
      "audio\\electronic\\94.mp3\n",
      "audio\\electronic\\95.mp3\n",
      "audio\\electronic\\96.mp3\n",
      "audio\\electronic\\97.mp3\n",
      "audio\\electronic\\98.mp3\n",
      "audio\\electronic\\99.mp3\n",
      "audio\\electronic\\100.mp3\n",
      "audio\\pop\\1.mp3\n",
      "audio\\pop\\2.mp3\n",
      "audio\\pop\\3.mp3\n",
      "audio\\pop\\4.mp3\n",
      "audio\\pop\\5.mp3\n",
      "audio\\pop\\6.mp3\n",
      "audio\\pop\\7.mp3\n",
      "audio\\pop\\8.mp3\n",
      "audio\\pop\\9.mp3\n",
      "audio\\pop\\10.mp3\n",
      "audio\\pop\\11.mp3\n",
      "audio\\pop\\12.mp3\n",
      "audio\\pop\\13.mp3\n",
      "audio\\pop\\14.mp3\n",
      "audio\\pop\\15.mp3\n",
      "audio\\pop\\16.mp3\n",
      "audio\\pop\\17.mp3\n",
      "audio\\pop\\18.mp3\n",
      "audio\\pop\\19.mp3\n",
      "audio\\pop\\20.mp3\n",
      "audio\\pop\\21.mp3\n",
      "audio\\pop\\22.mp3\n",
      "audio\\pop\\23.mp3\n",
      "audio\\pop\\24.mp3\n",
      "audio\\pop\\25.mp3\n",
      "audio\\pop\\26.mp3\n",
      "audio\\pop\\27.mp3\n",
      "audio\\pop\\28.mp3\n",
      "audio\\pop\\29.mp3\n",
      "audio\\pop\\30.mp3\n",
      "audio\\pop\\31.mp3\n",
      "audio\\pop\\32.mp3\n",
      "audio\\pop\\33.mp3\n",
      "audio\\pop\\34.mp3\n",
      "audio\\pop\\35.mp3\n",
      "audio\\pop\\36.mp3\n",
      "audio\\pop\\37.mp3\n",
      "audio\\pop\\38.mp3\n",
      "audio\\pop\\39.mp3\n",
      "audio\\pop\\40.mp3\n",
      "audio\\pop\\41.mp3\n",
      "audio\\pop\\42.mp3\n",
      "audio\\pop\\43.mp3\n",
      "audio\\pop\\44.mp3\n",
      "audio\\pop\\45.mp3\n",
      "audio\\pop\\46.mp3\n",
      "audio\\pop\\47.mp3\n",
      "audio\\pop\\48.mp3\n",
      "audio\\pop\\49.mp3\n",
      "audio\\pop\\50.mp3\n",
      "audio\\pop\\51.mp3\n",
      "audio\\pop\\52.mp3\n",
      "audio\\pop\\53.mp3\n",
      "audio\\pop\\54.mp3\n",
      "audio\\pop\\55.mp3\n",
      "audio\\pop\\56.mp3\n",
      "audio\\pop\\57.mp3\n",
      "audio\\pop\\58.mp3\n",
      "audio\\pop\\59.mp3\n",
      "audio\\pop\\60.mp3\n",
      "audio\\pop\\61.mp3\n",
      "audio\\pop\\62.mp3\n",
      "audio\\pop\\63.mp3\n",
      "audio\\pop\\64.mp3\n",
      "audio\\pop\\65.mp3\n",
      "audio\\pop\\66.mp3\n",
      "audio\\pop\\67.mp3\n",
      "audio\\pop\\68.mp3\n",
      "audio\\pop\\69.mp3\n",
      "audio\\pop\\70.mp3\n",
      "audio\\pop\\71.mp3\n",
      "audio\\pop\\72.mp3\n",
      "audio\\pop\\73.mp3\n",
      "audio\\pop\\74.mp3\n",
      "audio\\pop\\75.mp3\n",
      "audio\\pop\\76.mp3\n",
      "audio\\pop\\77.mp3\n",
      "audio\\pop\\78.mp3\n",
      "audio\\pop\\79.mp3\n",
      "audio\\pop\\80.mp3\n",
      "audio\\pop\\81.mp3\n",
      "audio\\pop\\82.mp3\n",
      "audio\\pop\\83.mp3\n",
      "audio\\pop\\84.mp3\n",
      "audio\\pop\\85.mp3\n",
      "audio\\pop\\86.mp3\n",
      "audio\\pop\\87.mp3\n",
      "audio\\pop\\88.mp3\n",
      "audio\\pop\\89.mp3\n",
      "audio\\pop\\90.mp3\n",
      "audio\\pop\\91.mp3\n",
      "audio\\pop\\92.mp3\n",
      "audio\\pop\\93.mp3\n",
      "audio\\pop\\94.mp3\n",
      "audio\\pop\\95.mp3\n",
      "audio\\pop\\96.mp3\n",
      "audio\\pop\\97.mp3\n",
      "audio\\pop\\98.mp3\n",
      "audio\\pop\\99.mp3\n",
      "audio\\pop\\100.mp3\n",
      "audio\\rock\\1.mp3\n",
      "audio\\rock\\2.mp3\n",
      "audio\\rock\\3.mp3\n",
      "audio\\rock\\4.mp3\n",
      "audio\\rock\\5.mp3\n",
      "audio\\rock\\6.mp3\n",
      "audio\\rock\\7.mp3\n",
      "audio\\rock\\8.mp3\n",
      "audio\\rock\\9.mp3\n",
      "audio\\rock\\10.mp3\n",
      "audio\\rock\\11.mp3\n",
      "audio\\rock\\12.mp3\n",
      "audio\\rock\\13.mp3\n",
      "audio\\rock\\14.mp3\n",
      "audio\\rock\\15.mp3\n",
      "audio\\rock\\16.mp3\n",
      "audio\\rock\\17.mp3\n",
      "audio\\rock\\18.mp3\n",
      "audio\\rock\\19.mp3\n",
      "audio\\rock\\20.mp3\n",
      "audio\\rock\\21.mp3\n",
      "audio\\rock\\22.mp3\n",
      "audio\\rock\\23.mp3\n",
      "audio\\rock\\24.mp3\n",
      "audio\\rock\\25.mp3\n",
      "audio\\rock\\26.mp3\n",
      "audio\\rock\\27.mp3\n",
      "audio\\rock\\28.mp3\n",
      "audio\\rock\\29.mp3\n",
      "audio\\rock\\30.mp3\n",
      "audio\\rock\\31.mp3\n",
      "audio\\rock\\32.mp3\n",
      "audio\\rock\\33.mp3\n",
      "audio\\rock\\34.mp3\n",
      "audio\\rock\\35.mp3\n",
      "audio\\rock\\36.mp3\n",
      "audio\\rock\\37.mp3\n",
      "audio\\rock\\38.mp3\n",
      "audio\\rock\\39.mp3\n",
      "audio\\rock\\40.mp3\n",
      "audio\\rock\\41.mp3\n",
      "audio\\rock\\42.mp3\n",
      "audio\\rock\\43.mp3\n",
      "audio\\rock\\44.mp3\n",
      "audio\\rock\\45.mp3\n",
      "audio\\rock\\46.mp3\n",
      "audio\\rock\\47.mp3\n",
      "audio\\rock\\48.mp3\n",
      "audio\\rock\\49.mp3\n",
      "audio\\rock\\50.mp3\n",
      "audio\\rock\\51.mp3\n",
      "audio\\rock\\52.mp3\n",
      "audio\\rock\\53.mp3\n",
      "audio\\rock\\54.mp3\n",
      "audio\\rock\\55.mp3\n",
      "audio\\rock\\56.mp3\n",
      "audio\\rock\\57.mp3\n",
      "audio\\rock\\58.mp3\n",
      "audio\\rock\\59.mp3\n",
      "audio\\rock\\60.mp3\n",
      "audio\\rock\\61.mp3\n",
      "audio\\rock\\62.mp3\n",
      "audio\\rock\\63.mp3\n",
      "audio\\rock\\64.mp3\n",
      "audio\\rock\\65.mp3\n",
      "audio\\rock\\66.mp3\n",
      "audio\\rock\\67.mp3\n",
      "audio\\rock\\68.mp3\n",
      "audio\\rock\\69.mp3\n",
      "audio\\rock\\70.mp3\n",
      "audio\\rock\\71.mp3\n",
      "audio\\rock\\72.mp3\n",
      "audio\\rock\\73.mp3\n",
      "audio\\rock\\74.mp3\n",
      "audio\\rock\\75.mp3\n",
      "audio\\rock\\76.mp3\n",
      "audio\\rock\\77.mp3\n",
      "audio\\rock\\78.mp3\n",
      "audio\\rock\\79.mp3\n",
      "audio\\rock\\80.mp3\n",
      "audio\\rock\\81.mp3\n",
      "audio\\rock\\82.mp3\n",
      "audio\\rock\\83.mp3\n",
      "audio\\rock\\84.mp3\n",
      "audio\\rock\\85.mp3\n",
      "audio\\rock\\86.mp3\n",
      "audio\\rock\\87.mp3\n",
      "audio\\rock\\88.mp3\n",
      "audio\\rock\\89.mp3\n",
      "audio\\rock\\90.mp3\n",
      "audio\\rock\\91.mp3\n",
      "audio\\rock\\92.mp3\n",
      "audio\\rock\\93.mp3\n",
      "audio\\rock\\94.mp3\n",
      "audio\\rock\\95.mp3\n",
      "audio\\rock\\96.mp3\n",
      "audio\\rock\\97.mp3\n",
      "audio\\rock\\98.mp3\n",
      "audio\\rock\\99.mp3\n",
      "audio\\rock\\100.mp3\n"
     ]
    }
   ],
   "source": [
    "def dataset_of_audio_files():\n",
    "    file_paths = []\n",
    "    audio_path = Path(\"audio\")\n",
    "    genres = audio_path.glob(\"*\")\n",
    "    for genre in genres:\n",
    "        for i in range(1, 101, 1):\n",
    "            path = Path(f\"{genre}/{i}.mp3\")\n",
    "            file_paths.append(str(path))\n",
    "    #file_paths = tf.data.Dataset.list_files(file_paths, shuffle=False)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "files = dataset_of_audio_files()\n",
    "for i in files:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for file in files:\n",
    "    data.append(load_audio(file))\n",
    "    #print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = tf.data.Dataset.from_tensor_slices(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tf.data.Dataset.zip((files, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, label):\n",
    "    # print(path)\n",
    "    # print(label)\n",
    "    #data = load_audio(path)\n",
    "    print(type(data))\n",
    "    spec = get_spec(data)\n",
    "    spec = tf.expand_dims(spec, axis=2)\n",
    "    return spec, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath, label = df.shuffle(buffer_size=10000).as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128, 625, 1), dtype=float32, numpy=\n",
       " array([[[3.9537158e+00],\n",
       "         [1.4197346e+00],\n",
       "         [3.7999487e+00],\n",
       "         ...,\n",
       "         [1.0299018e-02],\n",
       "         [4.7554126e+00],\n",
       "         [1.0526814e+00]],\n",
       " \n",
       "        [[4.8520637e+00],\n",
       "         [1.1690910e+01],\n",
       "         [7.0834265e+00],\n",
       "         ...,\n",
       "         [6.2473249e+00],\n",
       "         [5.2611828e+00],\n",
       "         [7.9552037e-01]],\n",
       " \n",
       "        [[4.7215958e+00],\n",
       "         [2.2125275e+01],\n",
       "         [6.5025191e+00],\n",
       "         ...,\n",
       "         [5.3360944e+00],\n",
       "         [5.2583590e+00],\n",
       "         [3.2273858e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[4.9004592e-03],\n",
       "         [4.5990077e-05],\n",
       "         [2.8599301e-05],\n",
       "         ...,\n",
       "         [3.1128709e-04],\n",
       "         [5.4183812e-04],\n",
       "         [7.0899630e-05]],\n",
       " \n",
       "        [[3.0781729e-03],\n",
       "         [1.4840771e-05],\n",
       "         [3.4470074e-06],\n",
       "         ...,\n",
       "         [1.2459928e-04],\n",
       "         [9.3565359e-05],\n",
       "         [1.8952254e-05]],\n",
       " \n",
       "        [[1.7276552e-03],\n",
       "         [6.7876645e-06],\n",
       "         [3.6378190e-06],\n",
       "         ...,\n",
       "         [7.2268289e-05],\n",
       "         [9.9945268e-05],\n",
       "         [8.2087790e-06]]], dtype=float32)>,\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram, label = preprocess(filepath, label)\n",
    "spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset element_spec=(TensorSpec(shape=(320000,), dtype=tf.float32, name=None), TensorSpec(shape=(9,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "ename": "ParameterError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\barto\\AppData\\Local\\Temp\\ipykernel_26276\\1592215474.py\", line 6, in preprocess  *\n        spec = get_spec(data)\n    File \"C:\\Users\\barto\\AppData\\Local\\Temp\\ipykernel_26276\\1248129145.py\", line 2, in get_spec  *\n        return np.abs(librosa.stft(y, n_fft=255, hop_length=512))\n    File \"e:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\librosa\\util\\decorators.py\", line 662, in inner_f  *\n        return f(*args, **kwargs)\n    File \"e:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\librosa\\core\\spectrum.py\", line 202, in stft  *\n        util.valid_audio(y, mono=False)\n    File \"e:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\librosa\\util\\decorators.py\", line 662, in inner_f  *\n        return f(*args, **kwargs)\n    File \"e:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\librosa\\util\\utils.py\", line 272, in valid_audio  *\n        raise ParameterError(\"Audio data must be of type numpy.ndarray\")\n\n    ParameterError: Audio data must be of type numpy.ndarray\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParameterError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [568], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mmap(preprocess)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2202\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2199\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[0;32m   2200\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2201\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2202\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   2203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2204\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[0;32m   2205\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[0;32m   2206\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2209\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   2210\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5400\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m   5399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[1;32m-> 5400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m   5401\u001b[0m     map_func,\n\u001b[0;32m   5402\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[0;32m   5403\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[0;32m   5404\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[0;32m   5405\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m   5406\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[0;32m   5407\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5408\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5411\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m   5412\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   2602\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2603\u001b[0m \n\u001b[0;32m   2604\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2610\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2611\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2612\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2613\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2574\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2576\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2577\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   2578\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2579\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    249\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileutaecfjf.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preprocess\u001b[1;34m(data, label)\u001b[0m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     10\u001b[0m ag__\u001b[39m.\u001b[39mld(\u001b[39mprint\u001b[39m)(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mtype\u001b[39m), (ag__\u001b[39m.\u001b[39mld(data),), \u001b[39mNone\u001b[39;00m, fscope))\n\u001b[1;32m---> 11\u001b[0m spec \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(get_spec), (ag__\u001b[39m.\u001b[39;49mld(data),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     12\u001b[0m spec \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mexpand_dims, (ag__\u001b[39m.\u001b[39mld(spec),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m), fscope)\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[0;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file5ivnuhfm.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__get_spec\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(np)\u001b[39m.\u001b[39mabs, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(librosa)\u001b[39m.\u001b[39;49mstft, (ag__\u001b[39m.\u001b[39;49mld(y),), \u001b[39mdict\u001b[39;49m(n_fft\u001b[39m=\u001b[39;49m\u001b[39m255\u001b[39;49m, hop_length\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m), fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filec2pclfh3.py:46\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m     45\u001b[0m args_msg \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39margs_msg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m ag__\u001b[39m.\u001b[39;49mif_stmt(ag__\u001b[39m.\u001b[39;49mld(extra_args) \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m, if_body, else_body, get_state, set_state, (\u001b[39m'\u001b[39;49m\u001b[39mdo_return\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mretval_\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39m2\u001b[39;49m)\n\u001b[0;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m fscope\u001b[39m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1363\u001b[0m, in \u001b[0;36mif_stmt\u001b[1;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[0;32m   1361\u001b[0m   _tf_if_stmt(cond, body, orelse, get_state, set_state, symbol_names, nouts)\n\u001b[0;32m   1362\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1363\u001b[0m   _py_if_stmt(cond, body, orelse)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1416\u001b[0m, in \u001b[0;36m_py_if_stmt\u001b[1;34m(cond, body, orelse)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_py_if_stmt\u001b[39m(cond, body, orelse):\n\u001b[0;32m   1415\u001b[0m   \u001b[39m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1416\u001b[0m   \u001b[39mreturn\u001b[39;00m body() \u001b[39mif\u001b[39;00m cond \u001b[39melse\u001b[39;00m orelse()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filec2pclfh3.py:28\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__inner_f.<locals>.if_body\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), \u001b[39mtuple\u001b[39;49m(ag__\u001b[39m.\u001b[39;49mld(args)), \u001b[39mdict\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(kwargs)), fscope)\n\u001b[0;32m     29\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileoohz_38a.py:179\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__stft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    178\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(hop_length) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m, if_body_1, else_body_1, get_state_1, set_state_1, (\u001b[39m'\u001b[39m\u001b[39mhop_length\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[1;32m--> 179\u001b[0m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(util)\u001b[39m.\u001b[39;49mvalid_audio, (ag__\u001b[39m.\u001b[39;49mld(y),), \u001b[39mdict\u001b[39;49m(mono\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), fscope)\n\u001b[0;32m    180\u001b[0m fft_window \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(get_window), (ag__\u001b[39m.\u001b[39mld(window), ag__\u001b[39m.\u001b[39mld(win_length)), \u001b[39mdict\u001b[39m(fftbins\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n\u001b[0;32m    181\u001b[0m fft_window \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(util)\u001b[39m.\u001b[39mpad_center, (ag__\u001b[39m.\u001b[39mld(fft_window),), \u001b[39mdict\u001b[39m(size\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(n_fft)), fscope)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filec2pclfh3.py:46\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m     45\u001b[0m args_msg \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39margs_msg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m ag__\u001b[39m.\u001b[39;49mif_stmt(ag__\u001b[39m.\u001b[39;49mld(extra_args) \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m, if_body, else_body, get_state, set_state, (\u001b[39m'\u001b[39;49m\u001b[39mdo_return\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mretval_\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39m2\u001b[39;49m)\n\u001b[0;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m fscope\u001b[39m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1363\u001b[0m, in \u001b[0;36mif_stmt\u001b[1;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[0;32m   1361\u001b[0m   _tf_if_stmt(cond, body, orelse, get_state, set_state, symbol_names, nouts)\n\u001b[0;32m   1362\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1363\u001b[0m   _py_if_stmt(cond, body, orelse)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1416\u001b[0m, in \u001b[0;36m_py_if_stmt\u001b[1;34m(cond, body, orelse)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_py_if_stmt\u001b[39m(cond, body, orelse):\n\u001b[0;32m   1415\u001b[0m   \u001b[39m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1416\u001b[0m   \u001b[39mreturn\u001b[39;00m body() \u001b[39mif\u001b[39;00m cond \u001b[39melse\u001b[39;00m orelse()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filec2pclfh3.py:28\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__inner_f.<locals>.if_body\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), \u001b[39mtuple\u001b[39;49m(ag__\u001b[39m.\u001b[39;49mld(args)), \u001b[39mdict\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(kwargs)), fscope)\n\u001b[0;32m     29\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filevm2tt4m6.py:76\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__valid_audio\u001b[1;34m(y, mono)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39melse_body\u001b[39m():\n\u001b[0;32m     75\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m ag__\u001b[39m.\u001b[39;49mif_stmt(ag__\u001b[39m.\u001b[39;49mnot_(ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39misinstance\u001b[39;49m), (ag__\u001b[39m.\u001b[39;49mld(y), ag__\u001b[39m.\u001b[39;49mld(np)\u001b[39m.\u001b[39;49mndarray), \u001b[39mNone\u001b[39;49;00m, fscope)), if_body, else_body, get_state, set_state, (), \u001b[39m0\u001b[39;49m)\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_1\u001b[39m():\n\u001b[0;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m ()\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1363\u001b[0m, in \u001b[0;36mif_stmt\u001b[1;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[0;32m   1361\u001b[0m   _tf_if_stmt(cond, body, orelse, get_state, set_state, symbol_names, nouts)\n\u001b[0;32m   1362\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1363\u001b[0m   _py_if_stmt(cond, body, orelse)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1416\u001b[0m, in \u001b[0;36m_py_if_stmt\u001b[1;34m(cond, body, orelse)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_py_if_stmt\u001b[39m(cond, body, orelse):\n\u001b[0;32m   1415\u001b[0m   \u001b[39m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1416\u001b[0m   \u001b[39mreturn\u001b[39;00m body() \u001b[39mif\u001b[39;00m cond \u001b[39melse\u001b[39;00m orelse()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filevm2tt4m6.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__valid_audio.<locals>.if_body\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mif_body\u001b[39m():\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mraise\u001b[39;00m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(ParameterError), (\u001b[39m'\u001b[39m\u001b[39mAudio data must be of type numpy.ndarray\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mParameterError\u001b[0m: in user code:\n\n    File \"C:\\Users\\barto\\AppData\\Local\\Temp\\ipykernel_26276\\1592215474.py\", line 6, in preprocess  *\n        spec = get_spec(data)\n    File \"C:\\Users\\barto\\AppData\\Local\\Temp\\ipykernel_26276\\1248129145.py\", line 2, in get_spec  *\n        return np.abs(librosa.stft(y, n_fft=255, hop_length=512))\n    File \"e:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\librosa\\util\\decorators.py\", line 662, in inner_f  *\n        return f(*args, **kwargs)\n    File \"e:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\librosa\\core\\spectrum.py\", line 202, in stft  *\n        util.valid_audio(y, mono=False)\n    File \"e:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\librosa\\util\\decorators.py\", line 662, in inner_f  *\n        return f(*args, **kwargs)\n    File \"e:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\librosa\\util\\utils.py\", line 272, in valid_audio  *\n        raise ParameterError(\"Audio data must be of type numpy.ndarray\")\n\n    ParameterError: Audio data must be of type numpy.ndarray\n"
     ]
    }
   ],
   "source": [
    "data = df.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 6.9058867e-15,  8.9184777e-15],\n",
      "       [ 8.9458385e-15,  6.1997518e-16],\n",
      "       ...,\n",
      "       [-3.4307002e-04, -1.2064925e-03],\n",
      "       [-1.9574368e-03, -2.5921764e-03],\n",
      "       [-2.7026713e-03, -2.9851031e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.00273895e-14, -2.51377237e-14],\n",
      "       [-8.34523626e-15, -1.32214084e-14],\n",
      "       ...,\n",
      "       [ 1.24788529e-03,  5.94543410e-04],\n",
      "       [ 9.44934145e-04,  5.10683865e-04],\n",
      "       [ 2.78530526e-04,  1.59415789e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.0736669e-14, -1.9630368e-14],\n",
      "       [ 2.8750060e-15,  5.3165446e-14],\n",
      "       ...,\n",
      "       [ 1.7368748e-04,  1.4062077e-03],\n",
      "       [ 8.2484161e-04,  1.3572222e-03],\n",
      "       [ 8.9762209e-04,  1.0587815e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-5.5980348e-15, -3.2978489e-15],\n",
      "       [-3.8187447e-15, -2.8120501e-15],\n",
      "       ...,\n",
      "       [-5.5929297e-04, -2.3408043e-03],\n",
      "       [-1.0337506e-03, -3.9375452e-03],\n",
      "       [-5.4380274e-05, -3.8750488e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 1, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-8.0587968e-15,  1.5761487e-15],\n",
      "       [-6.1133409e-15, -5.9344060e-15],\n",
      "       ...,\n",
      "       [-5.2131247e-05,  1.4086685e-04],\n",
      "       [-2.5604739e-05,  9.9959740e-05],\n",
      "       [-3.5442099e-06,  2.8518847e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.6091166e-14, -2.1892193e-13],\n",
      "       [-6.3218799e-14, -3.1721303e-14],\n",
      "       ...,\n",
      "       [-8.8548975e-04, -1.0038299e-03],\n",
      "       [-9.1828569e-04, -1.0294004e-03],\n",
      "       [-1.1324692e-03, -1.3697974e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-6.5952072e-14, -2.4812665e-14],\n",
      "       [ 1.0107488e-14,  3.4121597e-14],\n",
      "       ...,\n",
      "       [ 5.4611661e-04,  6.2027620e-04],\n",
      "       [ 1.3666932e-03,  5.2601745e-04],\n",
      "       [ 2.6880051e-03,  9.8873861e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.0358569e-14, -2.3484924e-14],\n",
      "       [-9.4517129e-15, -8.2749359e-16],\n",
      "       ...,\n",
      "       [ 3.6308981e-04,  9.1002315e-05],\n",
      "       [ 4.7841106e-04,  2.5319116e-04],\n",
      "       [ 1.7616316e-04,  3.6259022e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(1867392, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.7217801e-15,  7.4879989e-13],\n",
      "       [-9.5077754e-15,  2.7997930e-13],\n",
      "       ...,\n",
      "       [-1.8221341e-05, -5.4537326e-05],\n",
      "       [-1.3377639e-06, -5.9750557e-05],\n",
      "       [ 4.2132462e-05, -5.6011126e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.5132464e-14, -7.8589411e-14],\n",
      "       [ 1.4722471e-14, -6.7015593e-14],\n",
      "       ...,\n",
      "       [ 2.5048523e-04, -3.8105366e-04],\n",
      "       [ 1.4071503e-04, -3.5323290e-04],\n",
      "       [ 4.1404244e-04, -4.9662392e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 1, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 5.0873941e-14,  8.5463625e-15],\n",
      "       [ 3.5106517e-14,  2.7367351e-15],\n",
      "       ...,\n",
      "       [-3.3622549e-04, -8.3142199e-04],\n",
      "       [-3.2693648e-04, -3.5190862e-04],\n",
      "       [ 3.1305081e-04, -9.3870820e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.6028279e-14, -1.9431659e-14],\n",
      "       [ 1.6627924e-14, -3.6746085e-14],\n",
      "       ...,\n",
      "       [-1.4341618e-03,  5.1488332e-04],\n",
      "       [ 7.4572780e-04,  7.8268960e-04],\n",
      "       [-2.1443817e-04,  1.0915943e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 9.7629197e-16, -3.3003696e-16],\n",
      "       [ 2.5462632e-15,  5.2917939e-16],\n",
      "       ...,\n",
      "       [ 2.2512553e-03,  2.4238178e-03],\n",
      "       [ 1.1826885e-03,  1.5014738e-03],\n",
      "       [ 1.0897596e-03,  1.1299339e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.69235573e-15,  5.76853832e-15],\n",
      "       [-3.36613223e-15,  1.97976884e-15],\n",
      "       ...,\n",
      "       [-3.62186693e-05,  8.82370150e-05],\n",
      "       [ 1.48329491e-05,  5.90367235e-05],\n",
      "       [ 1.02849925e-04,  7.66265002e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 4.9225130e-14,  3.5911341e-14],\n",
      "       [ 4.6498097e-14,  5.1626285e-14],\n",
      "       ...,\n",
      "       [-1.9588770e-04, -1.0922600e-04],\n",
      "       [-2.1345646e-04,  1.0408021e-03],\n",
      "       [ 4.5208875e-05, -2.4839109e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.1339565e-15,  1.2717048e-15],\n",
      "       [ 2.0619198e-15,  7.3581413e-16],\n",
      "       ...,\n",
      "       [ 3.7628168e-04, -3.3903707e-05],\n",
      "       [ 2.2973452e-04,  6.1965075e-06],\n",
      "       [-2.4581529e-04,  4.7514273e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-7.4526146e-14,  8.9644946e-14],\n",
      "       [-7.0838246e-14,  7.1078004e-14],\n",
      "       ...,\n",
      "       [ 1.0943501e-03,  1.8032358e-03],\n",
      "       [ 3.0052534e-04,  4.8239261e-04],\n",
      "       [ 8.6030748e-05,  3.6953870e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 1, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.1583826e-13,  1.2984717e-13],\n",
      "       [-3.8897260e-13,  1.6640598e-13],\n",
      "       ...,\n",
      "       [ 8.6562731e-04,  7.3547836e-04],\n",
      "       [ 9.3990390e-04,  5.3736259e-04],\n",
      "       [ 1.2524707e-03,  3.0451483e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 3.2187760e-16, -2.4295615e-15],\n",
      "       [-2.8770762e-15, -6.9585823e-15],\n",
      "       ...,\n",
      "       [-1.1717695e-04, -2.3642131e-04],\n",
      "       [ 5.9191167e-04, -3.6982550e-05],\n",
      "       [ 6.0902257e-04, -1.4563161e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.2493566e-14, -3.5622059e-14],\n",
      "       [ 8.0790087e-15, -3.6250706e-15],\n",
      "       ...,\n",
      "       [ 6.0906762e-04, -9.4887670e-05],\n",
      "       [ 4.2238733e-04,  2.1882895e-03],\n",
      "       [ 3.3352496e-03,  1.5585436e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.7351436e-14,  2.1497791e-14],\n",
      "       [ 2.4817974e-14, -7.2851745e-15],\n",
      "       ...,\n",
      "       [-6.2569947e-05, -2.1643245e-05],\n",
      "       [-6.2303297e-05,  9.9608624e-06],\n",
      "       [-1.8251015e-04,  2.2636447e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.3046918e-15,  1.8449172e-17],\n",
      "       [ 2.7593775e-15, -5.2472039e-16],\n",
      "       ...,\n",
      "       [ 3.1223495e-05,  9.6078904e-04],\n",
      "       [ 1.7885011e-04,  4.2122352e-04],\n",
      "       [-5.7744328e-06,  5.1568961e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.8005883e-13,  3.2302936e-13],\n",
      "       [-3.5041468e-13,  1.7671444e-13],\n",
      "       ...,\n",
      "       [-2.1665376e-03,  1.2635419e-03],\n",
      "       [-1.3114356e-03, -3.0913641e-04],\n",
      "       [-7.9556607e-04, -5.0418515e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 8.1545276e-15,  9.4044035e-15],\n",
      "       [ 6.0762891e-15,  7.2664737e-15],\n",
      "       ...,\n",
      "       [ 7.9220999e-04,  2.8979062e-04],\n",
      "       [-4.4448892e-04,  6.1653368e-04],\n",
      "       [-1.6800461e-04,  5.6135678e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.3658975e-13, -4.4013306e-13],\n",
      "       [ 4.1286682e-13, -2.9885228e-13],\n",
      "       ...,\n",
      "       [ 1.3081182e-05, -3.5737094e-04],\n",
      "       [ 6.6744821e-04,  1.2821937e-04],\n",
      "       [-6.0868036e-04, -3.5861218e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-9.8984575e-15,  2.3373369e-14],\n",
      "       [-9.0416591e-15,  2.1350004e-14],\n",
      "       ...,\n",
      "       [ 5.6412726e-05, -2.6917878e-05],\n",
      "       [-3.6459329e-05, -1.1164895e-05],\n",
      "       [-7.0576396e-05, -1.7386987e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.6386914e-13, -1.4140897e-13],\n",
      "       [ 3.1225914e-13, -5.6714487e-14],\n",
      "       ...,\n",
      "       [ 4.5584301e-03, -3.3646133e-03],\n",
      "       [ 3.6207500e-03, -3.2852551e-03],\n",
      "       [-6.5736228e-04,  6.0085882e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-4.06827519e-14,  1.13570245e-14],\n",
      "       [-3.78293114e-14,  9.15283643e-15],\n",
      "       ...,\n",
      "       [ 1.53018720e-03, -1.11816466e-04],\n",
      "       [ 1.50808727e-03, -9.65476574e-05],\n",
      "       [ 9.95341688e-04, -3.78596305e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.1389330e-14, -1.5672508e-14],\n",
      "       [ 2.3759749e-14, -9.3267425e-15],\n",
      "       ...,\n",
      "       [-5.1870248e-03, -3.2638584e-03],\n",
      "       [-4.2073294e-03, -2.7113203e-03],\n",
      "       [-3.2231347e-03, -3.4640534e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 4.7049190e-15, -9.3504306e-16],\n",
      "       [-2.9791084e-14, -3.7260220e-14],\n",
      "       ...,\n",
      "       [ 3.6505045e-04, -6.0153694e-04],\n",
      "       [-5.0091236e-05,  8.9338422e-04],\n",
      "       [ 4.7512029e-04, -1.2909011e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.8001934e-14, -8.1047994e-13],\n",
      "       [ 7.7988356e-15, -5.6635447e-13],\n",
      "       ...,\n",
      "       [-6.3320383e-04,  3.7002959e-05],\n",
      "       [ 3.6653021e-04, -9.1646414e-04],\n",
      "       [ 1.5967462e-03,  9.8024099e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.7458301e-14,  4.2326987e-13],\n",
      "       [ 1.4249399e-13,  9.7588712e-14],\n",
      "       ...,\n",
      "       [-2.7983086e-04,  4.1235241e-04],\n",
      "       [ 3.7140740e-04,  7.5786724e-04],\n",
      "       [-2.8060554e-04,  1.2995690e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.6903098e-14, -3.9084231e-14],\n",
      "       [-1.2971764e-14, -1.3152012e-14],\n",
      "       ...,\n",
      "       [ 1.4829916e-04, -4.9433787e-05],\n",
      "       [ 2.8568382e-05, -8.6761516e-05],\n",
      "       [-4.3836404e-05, -8.1506165e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.2746314e-14, -4.0356410e-15],\n",
      "       [-3.9638838e-15, -5.5734124e-15],\n",
      "       ...,\n",
      "       [-1.1560627e-03, -6.5503776e-04],\n",
      "       [ 1.0060420e-04, -2.1373027e-04],\n",
      "       [ 1.3511546e-03,  1.5388470e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-8.78789991e-15, -1.68543226e-14],\n",
      "       [-1.18767944e-14,  1.52581398e-14],\n",
      "       ...,\n",
      "       [-4.42293640e-07,  4.92028084e-05],\n",
      "       [-1.24684142e-04,  2.83743921e-05],\n",
      "       [-1.07015774e-04, -5.88026160e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(1541884, 2), dtype=float32, numpy=\n",
      "array([[-6.1859728e-06, -3.7604321e-05],\n",
      "       [ 3.8384282e-05, -5.2441756e-05],\n",
      "       [ 8.7418462e-05, -2.5240270e-05],\n",
      "       ...,\n",
      "       [ 2.3580261e-04, -9.4810838e-04],\n",
      "       [ 6.1730971e-06, -9.1205444e-04],\n",
      "       [-1.3834180e-04, -4.8294239e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.0830806e-12, -8.9215939e-13],\n",
      "       [ 8.3842438e-13, -3.9032287e-13],\n",
      "       ...,\n",
      "       [ 4.2019767e-04, -4.2102771e-04],\n",
      "       [ 1.2344783e-04, -5.9454818e-04],\n",
      "       [-1.0281117e-04,  7.5780525e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 3.8558620e-14,  1.1748553e-13],\n",
      "       [ 2.8238791e-15,  1.2159768e-14],\n",
      "       ...,\n",
      "       [ 1.9061437e-04, -3.8244593e-04],\n",
      "       [ 2.6595895e-05, -5.5688008e-04],\n",
      "       [-9.4116534e-05, -4.2994498e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 5.5998365e-16,  4.7157361e-15],\n",
      "       [-2.9194236e-15,  1.3059469e-15],\n",
      "       ...,\n",
      "       [ 3.5959689e-05,  4.6394934e-04],\n",
      "       [ 2.7254428e-06,  1.1439222e-03],\n",
      "       [ 1.3102312e-04, -2.7395153e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([1, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.3119538e-15, -1.1263018e-16],\n",
      "       [-2.2330736e-15, -3.3681069e-16],\n",
      "       ...,\n",
      "       [ 7.9345959e-04,  4.4445042e-05],\n",
      "       [ 1.4279828e-03, -5.3466028e-05],\n",
      "       [ 1.1709904e-04,  8.6961911e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.4781787e-13,  2.8330196e-14],\n",
      "       [ 7.0851690e-14,  4.6061503e-14],\n",
      "       ...,\n",
      "       [-4.6916597e-05,  1.5752105e-04],\n",
      "       [-2.3923256e-04, -4.2652598e-04],\n",
      "       [-2.1130726e-04,  1.4118064e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 8.1223046e-14,  1.4186810e-13],\n",
      "       [-2.6573456e-13, -1.0362745e-13],\n",
      "       ...,\n",
      "       [-6.6126086e-04, -4.7897131e-04],\n",
      "       [ 5.5266067e-04, -1.2582301e-03],\n",
      "       [ 1.2746858e-03,  7.1483967e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.8804786e-15,  5.7485024e-16],\n",
      "       [ 2.1241801e-15,  6.5497823e-16],\n",
      "       ...,\n",
      "       [-4.8665272e-04, -4.5146246e-04],\n",
      "       [-5.9731613e-04,  9.3974377e-06],\n",
      "       [ 2.8464617e-04,  6.1391620e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.8533440e-15,  4.3778058e-14],\n",
      "       [ 2.9483672e-14,  6.1735976e-14],\n",
      "       ...,\n",
      "       [-3.3881079e-04,  1.5993200e-03],\n",
      "       [-1.5920557e-03,  3.3093514e-03],\n",
      "       [-9.5852389e-04, -1.3611098e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.4216043e-15, -3.2289574e-16],\n",
      "       [-2.6695412e-15,  4.7524122e-15],\n",
      "       ...,\n",
      "       [ 1.3400858e-03, -1.2176870e-03],\n",
      "       [ 1.4991276e-03, -7.1586511e-04],\n",
      "       [ 1.3947811e-03, -1.8592460e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 1], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-7.5966330e-16,  3.5433470e-15],\n",
      "       [ 4.5852922e-16,  6.6665754e-15],\n",
      "       ...,\n",
      "       [ 4.2676835e-05,  5.8048452e-05],\n",
      "       [-6.4899796e-05, -3.5260524e-05],\n",
      "       [-2.2401582e-07,  1.0396627e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2630016, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.4572674e-15,  1.3387644e-15],\n",
      "       [-5.5192201e-16,  3.2556787e-15],\n",
      "       ...,\n",
      "       [-3.0178622e-08,  1.8456022e-08],\n",
      "       [-5.6327785e-08, -9.6927213e-09],\n",
      "       [-1.9904459e-08,  2.4228365e-08]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.4803337e-14, -7.7567618e-15],\n",
      "       [-1.0750718e-14,  4.5017978e-14],\n",
      "       ...,\n",
      "       [-6.6823710e-04,  1.4710698e-03],\n",
      "       [-7.8429829e-04,  8.2618475e-04],\n",
      "       [-2.0372120e-04,  8.1596372e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.0376925e-14, -5.6449156e-15],\n",
      "       [ 5.5770547e-15,  1.0450830e-14],\n",
      "       ...,\n",
      "       [-5.2928808e-05, -9.8783383e-04],\n",
      "       [ 1.7359180e-04, -9.7410090e-04],\n",
      "       [ 6.3053292e-04, -1.0842485e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 1, 0, 0, 0, 0, 0, 0, 1], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.0303522e-15,  2.2237471e-15],\n",
      "       [-9.5613291e-16,  1.9463034e-15],\n",
      "       ...,\n",
      "       [-5.7027268e-04,  1.0244427e-03],\n",
      "       [ 2.2727129e-04,  1.9997587e-04],\n",
      "       [ 1.2993716e-03, -2.4398579e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-6.6337926e-17,  8.6015857e-16],\n",
      "       [-1.0122968e-14,  2.9576408e-15],\n",
      "       ...,\n",
      "       [ 1.3153402e-04,  9.4110357e-05],\n",
      "       [-6.7039940e-04,  4.7340371e-05],\n",
      "       [ 7.3386473e-05, -6.3158179e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.5251718e-16, -2.7293545e-15],\n",
      "       [-3.3481476e-16,  1.1198739e-15],\n",
      "       ...,\n",
      "       [-8.6078467e-04, -5.4620771e-04],\n",
      "       [ 8.8393979e-05, -2.1237286e-04],\n",
      "       [ 5.0846767e-04, -2.2460590e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.3892656e-15, -6.7435067e-16],\n",
      "       [-1.5844408e-15,  1.7485031e-16],\n",
      "       ...,\n",
      "       [ 1.2363530e-04,  6.8558252e-04],\n",
      "       [ 2.7445087e-04,  1.2784621e-03],\n",
      "       [-1.2958597e-05,  5.8492785e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 1, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2576132, 2), dtype=float32, numpy=\n",
      "array([[-5.2285999e-05,  5.1936495e-06],\n",
      "       [-3.4630873e-05, -7.2932926e-06],\n",
      "       [ 2.1673193e-05,  3.3719734e-06],\n",
      "       ...,\n",
      "       [ 1.1483416e-03,  1.7560779e-03],\n",
      "       [ 1.3641394e-03,  2.0057401e-03],\n",
      "       [ 1.1165141e-03,  1.5598807e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.2384639e-12,  4.1458590e-14],\n",
      "       [-1.5460615e-14, -1.4014216e-13],\n",
      "       ...,\n",
      "       [ 1.7452016e-04,  1.4817980e-04],\n",
      "       [-1.7376668e-05,  6.5427266e-05],\n",
      "       [-2.1123581e-04, -7.8116922e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.6281139e-14,  1.6928257e-14],\n",
      "       [-9.4436178e-15,  7.8547991e-15],\n",
      "       ...,\n",
      "       [ 2.6805918e-03, -1.5232924e-03],\n",
      "       [ 3.3764832e-03, -9.1040437e-04],\n",
      "       [ 3.1473143e-03,  1.4605693e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.8018498e-14,  6.2589128e-16],\n",
      "       [-4.5689780e-14, -1.7698986e-15],\n",
      "       ...,\n",
      "       [ 2.0461695e-05, -3.0863818e-04],\n",
      "       [-2.8135264e-04, -3.8104685e-04],\n",
      "       [ 4.8420834e-04, -8.4453431e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.0067110e-14,  6.9550180e-15],\n",
      "       [-7.2693138e-15,  1.0599138e-14],\n",
      "       ...,\n",
      "       [-1.2282182e-04, -1.2236951e-04],\n",
      "       [-1.6330759e-04, -4.4140784e-04],\n",
      "       [-1.4820040e-04,  1.5320491e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 3.59369144e-15,  1.21715365e-14],\n",
      "       [ 3.30302124e-14,  7.52907089e-15],\n",
      "       ...,\n",
      "       [ 3.53018346e-04,  8.95685389e-06],\n",
      "       [ 9.56390140e-05, -8.17750333e-07],\n",
      "       [ 1.02635255e-04,  4.60105184e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.1382005e-18,  1.5131917e-15],\n",
      "       [-2.3066704e-15,  9.0191009e-17],\n",
      "       ...,\n",
      "       [-8.3791313e-04, -3.9102236e-04],\n",
      "       [-1.3753141e-03, -6.1842176e-04],\n",
      "       [-1.6609388e-03, -7.6370029e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 1, 1, 0, 0, 0, 1], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.2311246e-15, -3.3107130e-15],\n",
      "       [-4.5961545e-15,  5.0829880e-15],\n",
      "       ...,\n",
      "       [-3.2020795e-05,  1.6212645e-05],\n",
      "       [-1.7272600e-05,  1.8809542e-05],\n",
      "       [ 3.3062883e-05, -5.4856728e-06]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.4378979e-14, -9.1104831e-16],\n",
      "       [ 1.6759577e-14, -8.1146815e-16],\n",
      "       ...,\n",
      "       [-1.0461915e-04, -2.1034764e-05],\n",
      "       [-1.2140094e-04,  2.4180081e-06],\n",
      "       [-6.2654770e-05,  2.0104231e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.5103036e-14,  1.2444642e-15],\n",
      "       [-3.5164431e-14,  6.8193776e-16],\n",
      "       ...,\n",
      "       [ 5.4520830e-03,  3.7880812e-03],\n",
      "       [ 2.2857455e-03,  1.7242678e-03],\n",
      "       [-3.6072667e-04,  6.2185689e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(1139328, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.2991537e-14, -2.3737507e-14],\n",
      "       [ 1.1513353e-14, -1.8082341e-14],\n",
      "       ...,\n",
      "       [ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 3.7760122e-13, -1.6406698e-15],\n",
      "       [ 5.8226021e-14, -1.1146713e-14],\n",
      "       ...,\n",
      "       [-8.7882427e-04, -1.0235691e-04],\n",
      "       [ 2.8401404e-04,  2.8749113e-04],\n",
      "       [-4.2174413e-04,  1.8378660e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 4.2564621e-15, -5.9034334e-15],\n",
      "       [ 1.9059046e-15, -4.2016290e-15],\n",
      "       ...,\n",
      "       [-1.0481119e-03,  5.8154536e-05],\n",
      "       [-6.6891307e-04, -9.1167091e-04],\n",
      "       [-1.0446417e-03, -1.6498542e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.5306719e-14, -1.4169601e-14],\n",
      "       [-3.0336133e-14,  1.9117237e-14],\n",
      "       ...,\n",
      "       [-9.7261465e-05,  1.4222079e-04],\n",
      "       [ 1.2622012e-03,  1.6543736e-03],\n",
      "       [ 5.2610936e-04,  5.4319930e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.7976438e-14, -5.1701590e-13],\n",
      "       [ 4.4236702e-15, -7.8826680e-13],\n",
      "       ...,\n",
      "       [-1.3663708e-03, -7.1885547e-04],\n",
      "       [-1.4133246e-03, -1.0297883e-03],\n",
      "       [-1.6500739e-03, -1.1100422e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 3.7059589e-15, -2.1601908e-14],\n",
      "       [-3.3162939e-14, -1.1529838e-14],\n",
      "       ...,\n",
      "       [ 7.7922730e-04, -2.6479978e-04],\n",
      "       [ 2.0604979e-04, -1.3638109e-04],\n",
      "       [ 2.1266169e-04, -1.3894915e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 1, 1, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.2739636e-15, -5.0109991e-14],\n",
      "       [-1.0121278e-14,  3.6807444e-15],\n",
      "       ...,\n",
      "       [ 1.4744047e-04, -2.0701420e-03],\n",
      "       [ 4.0407022e-04, -1.0981150e-03],\n",
      "       [ 5.2032195e-04,  1.3231911e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[0.0000000e+00, 0.0000000e+00],\n",
      "       [1.8531938e-12, 7.7066733e-13],\n",
      "       [1.6284164e-12, 6.1031177e-13],\n",
      "       ...,\n",
      "       [5.6148652e-04, 1.9280479e-04],\n",
      "       [6.4384617e-04, 3.3128023e-04],\n",
      "       [2.7587713e-04, 3.4098644e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(1335168, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.3287195e-12, -5.1824479e-13],\n",
      "       [ 3.3537946e-13, -3.9152346e-13],\n",
      "       ...,\n",
      "       [ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.9321191e-14,  8.5342999e-15],\n",
      "       [-3.8143086e-14,  1.2212294e-14],\n",
      "       ...,\n",
      "       [ 1.2262458e-03, -3.2982058e-04],\n",
      "       [ 8.4512867e-04,  2.3700566e-05],\n",
      "       [-1.2406318e-03, -1.4825629e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.3484639e-14, -7.2603186e-13],\n",
      "       [-2.1033520e-14, -1.0416810e-12],\n",
      "       ...,\n",
      "       [-6.9663904e-05,  3.5832258e-05],\n",
      "       [-2.2924322e-04, -3.4437966e-05],\n",
      "       [ 2.3852146e-05,  4.1265768e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.7208422e-14,  3.3601783e-14],\n",
      "       [-5.8210659e-14, -5.1821205e-15],\n",
      "       ...,\n",
      "       [ 1.9209570e-03,  2.2835494e-03],\n",
      "       [ 2.1533419e-03,  2.1766089e-03],\n",
      "       [ 1.4447077e-03, -6.6327694e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.2660159e-15,  8.5212362e-17],\n",
      "       [-3.4001842e-15,  3.0804729e-15],\n",
      "       ...,\n",
      "       [ 1.0804568e-03,  3.5238307e-05],\n",
      "       [ 5.6864735e-04, -1.8274793e-04],\n",
      "       [ 7.6563651e-04,  3.1884926e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.9284420e-13, -3.3656162e-13],\n",
      "       [ 4.6983316e-13,  2.8276670e-14],\n",
      "       ...,\n",
      "       [ 7.4949826e-04, -6.5360870e-04],\n",
      "       [ 5.3653854e-04, -6.9077461e-05],\n",
      "       [ 3.1877591e-04,  7.5496879e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.3219228e-14,  1.8211509e-15],\n",
      "       [ 7.2264311e-15,  2.6250299e-15],\n",
      "       ...,\n",
      "       [-3.0536292e-04, -7.0619537e-04],\n",
      "       [-3.4257723e-04, -5.2969129e-04],\n",
      "       [-4.6434975e-04, -4.5944733e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.4239358e-15,  3.6040998e-15],\n",
      "       [ 3.3644288e-15,  4.3939847e-15],\n",
      "       ...,\n",
      "       [-1.4866147e-03,  9.2648307e-04],\n",
      "       [-3.5989815e-03, -4.4538005e-04],\n",
      "       [-1.6072087e-03,  1.2024832e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.3510656e-14,  4.1621105e-14],\n",
      "       [ 8.1063940e-14,  5.6207649e-14],\n",
      "       ...,\n",
      "       [ 3.9291914e-04,  1.7898218e-04],\n",
      "       [-6.7194283e-04,  3.7163915e-04],\n",
      "       [-4.2199335e-04,  2.0861841e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 3.3540672e-13,  2.7909546e-13],\n",
      "       [ 2.3058356e-13,  1.3964311e-12],\n",
      "       ...,\n",
      "       [-1.0076201e-05, -3.7148566e-06],\n",
      "       [-3.2413747e-05, -3.1145022e-04],\n",
      "       [-2.9966046e-04, -8.0734736e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.7381783e-14, -4.7972271e-13],\n",
      "       [ 2.0282109e-14, -2.7845911e-13],\n",
      "       ...,\n",
      "       [-8.1128674e-05, -3.4211008e-04],\n",
      "       [-9.3330571e-05, -3.1948008e-04],\n",
      "       [-9.3377894e-05, -4.5036813e-04]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 1, 1, 1, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.1608166e-15,  5.3364262e-16],\n",
      "       [ 3.6350800e-16, -3.6778838e-16],\n",
      "       ...,\n",
      "       [-2.4953581e-05,  5.7967816e-05],\n",
      "       [ 7.3205592e-05,  1.2222581e-05],\n",
      "       [ 9.3392766e-05,  6.3018204e-05]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(2647296, 2), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.2125843e-13,  4.8796606e-14],\n",
      "       [-1.0452094e-13,  4.7286123e-14],\n",
      "       ...,\n",
      "       [ 5.1156059e-04,  9.6448878e-04],\n",
      "       [ 9.1457623e-05,  2.0179526e-04],\n",
      "       [ 9.5358345e-04,  1.1302438e-03]], dtype=float32)>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [516], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data:\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(i)\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[0;32m    767\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[0;32m    750\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[0;32m    751\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[0;32m    752\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[0;32m    754\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32me:\\coding\\github\\audio-music-emotion-classification\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3011\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3009\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3010\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3011\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3012\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIteratorGetNext\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, iterator, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[0;32m   3013\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[0;32m   3014\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62a753bdee04e4331bca995ddc0459c11c39187c6e9b4d43311428dd6e14218d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
